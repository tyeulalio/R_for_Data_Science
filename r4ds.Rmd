---
title: "R for Data Science"
output:
  html_document:
    toc: true
    toc_depth: 4
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'index.html'))})

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

<a id="top"></a>


This work comes from following along with the **R for Data Science** book. The book is freely available online at https://r4ds.had.co.nz/ 

# Chapter 1: Introduction


```{r, message=FALSE, warning=FALSE}
# import the tidyverse library
library(tidyverse)

# update packages
# tidyverse_update()

# load other packages required for the book
library(nycflights13)
```

# Chapter 2: Introduction
[Back to Top](#top)

*We'll skill Chapter 2 since there's not much to write up there*

# Chapter 3: Data Visualization
[Back to Top](#top)

## 3.2 First Steps
Use the `mpg` data frame and visualization techniques to answer this question: Do cars with big engines use more fuel than cars with small engines?

### 3.2.1 The `mpg` data frame
[Back to Top](#top)

The `mpg` dataframe is included in the `ggplot2` package. It contains data on 38 car models, collected by the US Environmental Protection Agency.
```{r}
mpg
```

We can use `?mpg` to get more information on the dataframe.

The dataframe has 234 rows with the following 11 variables:

1) manufacturer - manufacturer name
2) model - model name
3) displ - engine displacement, in litres
4) year - year of manufacture
5) cyl - number of cylinders
6) trans - type of transmission
7) drv - the type of drive train, where f = front-wheel drive, r = rear wheel drive, 4 = 4wd
8) cty - city miles per gallon
9) hwy - highway miles per gallon
10) fl - fuel type
11) class - "type" of car

### 3.2.2 Creating a ggplot
[Back to Top](#top)

Plot `disp` on the x-axis and `hwy` on the y-axis.

```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy))
```
Notice the negative relationship between engine size (`displ`) and highway fuel efficiency (`hwy`), indicating that cars with big engines use more fuel.

*Not in book:* Let's try this with city mileage as well.
```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = cty))
```

Looks pretty much the same as highway mileage.

### Notes on `ggplot`
The call to `ggplot()` create a coordinate system which we'll add layers to. We connect a dataset to the plot using the `data` argument. This creates an empty plot.


### 3.2.4 Exercises
<a id="top"></a>

1) Run ggplot(data = mpg). What do you see?
```{r}
ggplot(data = mpg)
```

Just a blank figure.

2) How many rows are in mpg? How many columns?
```{r}
# rows in mpg
print(paste("rows =", nrow(mpg)))

# columns in mpg
print(paste("columns =", ncol(mpg)))
```


3) What does the drv variable describe? Read the help for ?mpg to find out.
?mpg
`drv` describes the type of drive train in the vehicle, where 

* f = front-wheel drive
* r = rear-wheel drive
* 4 = 4-wheel drive

4) Make a scatterplot of hwy vs cyl.
```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = hwy, y = cyl))
```


5) What happens if you make a scatterplot of class vs drv? Why is the plot not useful?
```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = class, y = drv))
```

This is not useful because both of these variables are categorical. We're not gaining much information by displaying the data as a scatter plot.

## 3.3 Aesthetic mappings
<a id="top"></a>

Mapping aestetics in your plot to variables in the data can help to illuminate interesting patterns. Let's map the `class` cariable to a plot of `displ` and `hwy` to see how those distribute.
```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, color = class))
```

We've mapping the colors of the points to the class variable. The `2seater` class seem to be outliers with large engines and good hwy mileage. This makes sense because these sports cars have large engines with small bodies.

We can also map variables to the `size` aesthetic. It's best not to map size to a categorical variable.
```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, size = class))
```

We also have the `alpha` or `shape` aesthetics.
```{r}
# Left
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, alpha = class))

# Right
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, shape = class))
```

The `shapes` aesthetic can only map six categories, and the rest will not be included.

You can also set the aesthetic properties manually. When the aesthetic is set manually (and not depending on a variable), it must be set OUTSIDE of the `aes` call.
```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy), color = 'blue')
```

### 3.3.1 Exercises
<a id="top"></a>

1) What’s gone wrong with this code? Why are the points not blue?
`ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, color = "blue"))`

The `color` is set manually, so it needs to be outside of the `aes()` call.


2) Which variables in mpg are categorical? Which variables are continuous? (Hint: type ?mpg to read the documentation for the dataset). How can you see this information when you run mpg?
?mpg
str(mpg)

The **categorical** variables are:

* manufactuerer
* model
* year
* cyl
* trans
* drv
* cty
* hwy
* fl
* class

The **continuous** variables are:

* displ

When we look at the `mpg` dataframe. We can look at the type of data that is in each column. `chr` variables are categorical. `num` variables are continuous. `int` variables aren't technically categorical nor continuous. Treating them as categorical is actually reducing the information that we have, so we might want to consider them as ordinal.


3) Map a continuous variable to color, size, and shape. How do these aesthetics behave differently for categorical vs. continuous variables?

Continuous Case:
```{r}
# map color
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, color = displ))

# map size
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, size = displ))

# map shape - doesn't work
# ggplot(data = mpg) +
#   geom_point(mapping = aes(x = displ, y = hwy, shape = displ))
```

Categorical Case:
```{r}
# map color
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, color = drv))

# map size
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, size = drv))

# map shape
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, shape = drv))
```

Shape doesn't map with a continuous variable. Color takes on a gradient.

Size doesn't work well with a categorical variable.


4) What happens if you map the same variable to multiple aesthetics?
```{r}
# map color and size
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, color = displ, size = displ))
```

We get both of the aesthetics on the same plot.


5) What does the stroke aesthetic do? What shapes does it work with? (Hint: use ?geom_point)
?geom_point
```{r}
# map color
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, stroke = 5))
```

The stroke aesthetic modifies the width of the border for each point.


6) What happens if you map an aesthetic to something other than a variable name, like aes(colour = displ < 5)? Note, you’ll also need to specify x and y.
```{r}
# map color
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, color = displ < 5))
```

We can set functions to set the aesthetics according to the data.


## 3.5 Facets
<a id="top"></a>

**Facets** allow us to split plots into multiple *subplots*. We can facet the plot by a single variable using `facet_wrap()`. The first argument of `facep_wrap()` is a formula which specifies the variable to so split the plot on.
```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_wrap(~ class, nrow = 2)
```

We can facet the plot on the combination to two variables as well, using `facet_grid()`. 
```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(drv ~ cyl)
```

To avoid rows and columns, we can use `.` instead of a variable name.
```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, 
                           color = class)) +
  facet_grid(. ~ class)
```


### 3.5.1 Exercises
<a id="top"></a>

1) What happens when you facet on a continuous variable?

```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(drv ~ cty)
```


Creating the facet using a continuous variable splits up the graph into each of the continuous values, resulting in a terrible graph.

2) What do the empty cells in plot with `facet_grid(drv ~ cyl)` mean? 
```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(drv ~ cyl)
```

The empty plots are facets that did not have any corresponding data. For instance, rear-wheel-drive did not have any cars with engine displacement (`displ`) of 4 or 5 litres.


How do they relate to this plot?
```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = drv, y = cyl))
```

We see that we're missing points at each of the variable combinations that aren't present in our dataset.


3) What plots does the following code make? What does `.` do?

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(drv ~ .)

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(. ~ cyl)
```

We create facets using just one variable. The `.` retains the rows or columns so that we don't tile in that direction.


4) Take the first faceted plot in this section:
```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_wrap(~ class, nrow = 2)
```

What are the advantages to using faceting instead of the color aesthetic? What are the disadvantages? How might the balance change if you had a larger dataset?

We can look at the color aesthetic here to compare.
```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, color = class))
```

One thing we can see immediately is that the overlapping points make it more difficult to look at a single group when we use the color aesthetic compared to the facet aesthetic. If we're interested in comparing points and looking for patterns within groups, then the facet aesthetic is more usefule here.

A disadvantage of using facets is that we lose some ability to compare across groups. With the color aesthetic, we immediately see how groups are mixed into one another, but this is less obvious with the facets. 

Depending on how many groups we're comparing, each of these aesthetics will change as well. If we have too many groups, facets will quickly become overwhelming to look at. In larger datasets with fewer groups, we might prefer to separate groups using facets so that we have less density per plot.

5) Read `?facet_wrap`. What does `nrow` do? What does `ncol` do? What other options control the layout of the individual panels? Why doesn't `facet_grid()` have `nrow` and `ncol` arguments?

The `facet_wrap` function wraps a sequence of panels into a 2-dimensional figure. The `nrow` and `ncol` arguments allow you to define the number of rows and columns for the wrapped figure.

The `as.table` option controls the order of the panels in the output. If `as.table` is TRUE (default), then te highest values will be at the bottom-right, otherwise, the highest value is at the top-left.

The `dir` option specifies whether the direction should be "h" for horizontal (default) or "v" for vertical.

`facet_grid()` does not have the `nrow` or `ncol` argumetns because we pass in the `rows` and `cols` arguments to define the groups that will create the rows and columns of the grid.


6) When using `facet_grid()` you should usually put the variable wit more unique levels in the columns. Why?

This would create a landscape figure rather than a tall portait figure.

```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(year ~ cyl)
```

```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(cyl ~ year)
```

The graphs are clearer and easier to read when we put the variable with more levels into the columns.

## 3.6 Geometric Objects
<a id="top"></a>

Plots can represent the same data with different visual objects. These are referred to as **geoms**. Take the following two graphs for example.
```{r}
# scatter plot
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy))

# line plot
ggplot(data=mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy))
```

Every geom in ggplot2 takes a `mapping` argument, however not every aesthetic can work with every geom. For instance, you can set the shape of a point, but not of a line.

Linetype can be set for a line.
```{r}
ggplot(data = mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))
```

The `drv` variable describes the car's drivetrain, which include 4-wheel-drive, forward-wheel-drive, and rear-wheel-drive. We've set the aesthetic to separate the data according to drivetrain and the linetype reflects each group.

We can see this even more clearly by overlapping multiple geoms on one plot. 
```{r}
ggplot(data = mpg, aes(x = displ, y = hwy)) +
  geom_smooth(mapping = aes(linetype = drv, color = drv)) +
  geom_point(mapping = aes(color = drv))
```

Here are some resources for the different geoms available for ggplot2:

* https://exts.ggplot2.tidyverse.org/gallery/
* http://rstudio.com/cheatsheets

Geoms like `geom_smooth()` use a single object to represent the data. We can set the `group` aesthetic to split the object into multiple groups. The convenient thing about the `group` feature is that a legend is not added automatically to our plot.
```{r}
ggplot(data = mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy, group = drv))
```

We can also manually remove the legend from aesthetics that do generate one, such as the `color` aesthetic.
```{r}
ggplot(data = mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy, 
                            group = drv, color = drv),
                            show.legend = FALSE)
```

To include multiple geoms in the same plot, we just add them to the same `ggplot()` function.
```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy)) +
  geom_smooth(mapping = aes(x = displ, y = hwy))
```

By writing the code like this, we duplicate the $x$ and $y$ axis assignments. This could make things difficult for updating these axes to different variables. Instead, we can add these assignments to the `ggplot()` function where they serve as global variables.
```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_point() +
  geom_smooth()
```

You can still extend or overwrite the global mappings by placing them directly in the geom function. 
```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_point(mapping = aes(color = class)) +
  geom_smooth()
```

You can use this to specify different data for the geoms as well. Here, we'll subset the smooth line to just the subcompact cars.
```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_point(mapping = aes(color = class)) +
  geom_smooth(data = filter(mpg, class == 'subcompact'), 
              se = FALSE)
```

### 3.6.1 Exercises
<a id="top"></a>

1) What geom would you use to draw a

* line chart? `geom_line()`
* boxplot? `geom_boxplot()`
* histogram? `geom_histogram()`
* area chart? `geom_area()`

2) Run this code in your head and predict what the output will look like. Then run the code in R and check your prediction.

**Prediction:** Map a scatter plot of `displ` against `hwy`, colored by `drv`. Includes smooth lines, also separated by `drv` and without standard errors.

```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) +
  geom_point() +
  geom_smooth(se = FALSE)
```

3) What does `show.legend = FALSE` do? What happens if you remove it? Why do you think I used it earlier in the chapter.

The `show.legend` flag indicates whether a legend should be included in the plot. It was probably used earlier because the legend only pertained to one of the plots.

4) What does the `se` argument to `geom_smooth()` do?
The `se` argument indicates whether the standard error region associated with the smooth line should be displayed.

```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + 
  geom_point() + 
  geom_smooth(se = TRUE)
```

5) Will these two graphs look different? Why/Why not?

**Prediction:** No, because the first plot simply sets global aesthetics, while the second plot sets the same aesthetics locally.

```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point() + 
  geom_smooth()

ggplot() + 
  geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy))
```

6) Recreate the R code necessary to generate the following graphs.

Top left graph:
```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_point(size=4) +
  geom_smooth(se = FALSE, size=2)
```

Top right plot:
```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_point(size=4) +
  geom_smooth(se = FALSE, size=2, mapping = aes(group = drv))
```

Middle left plot:
```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) +
  geom_point(size=4) +
  geom_smooth(se = FALSE, size=2, mapping = aes(group = drv))
```

Middle right plot:
```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_point(size=4, mapping = aes(color = drv)) +
  geom_smooth(se = FALSE, size=2)
```

Bottom left plot:
```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_point(size=4, mapping = aes(color = drv)) +
  geom_smooth(se = FALSE, size=2, mapping = aes(linetype = drv))
```

Bottom right plot:
```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_point(size=6, color = 'gray97') +
  geom_point(size=3, mapping = aes(color = drv))
```



## 3.7 Statistical transformations
<a id="top"></a>

Bar charts are a useful way to look at data. Here's a bar chart using the `diamonds` dataset, groupbed by `cuts`. This dataset contiains information about ~54,000 diamonds, including price, carat, color, clarity and cut of each diamond. We can see from the plot that more diamonds are available with high quality cuts than with low quality cuts.
```{r}
names(diamonds)

ggplot(data = diamonds) +
  geom_bar(mapping = aes(x=cut))
```

The $y$-axis variable, *count* is not in the `diamonds` dataset. Some graphs create new values to plot. 

* bar charts, histograms, and frequency polygons bin your data and then plot bin counts
* smoothers fit a model to your data and then plot predictions from the model
* boxplots compute summary statistics about the distribution and then display the formatted box

The algorithm used to produce the transformation is called a **stat** (i.e. statistical tranformation). You can get more info about what stat a geom uses by inspecting its default `stat` argument. For examples, `?geom_bar` shows us the the `stat` is "count", which means that it uses the `stat_count()` function. 

You can generally use stats and geoms interchangably. This produces the same graph as before,
```{r}
ggplot(data=diamonds) +
  stat_count(mapping = aes(x=cut))
```

Every geom has a default stat and every stat has a default geom.

There are three reason why you might want to select a stat specifically:

1) You want to override the default stat. Here we want to create a barchart where the actual data values are represented rather than counts.
```{r}
demo <- tribble(
  ~cut,         ~freq,
  "Fair",       1610,
  "Good",       4906,
  "Very Good",  12082,
  "Premium",    13791,
  "Ideal",      21551
)

ggplot(data = demo) +
  geom_bar(mapping = aes(x = cut, y = freq), stat = "identity")
```

2) You might want to override the default mapping from transformed variables to aesthetics. Here we display a bar chart for proportions rather than counts.
```{r}
ggplot(data=diamonds) +
  geom_bar(mapping = aes(x=cut, y=stat(prop), group=1))
```

3) You might want to emphasize the statistical transformation in your code. Here we use `stat_summary()` to summarize the y values for each unique x value to draw attention to the summary that we're computing.
```{r}
ggplot(data=diamonds) +
  stat_summary(
    mapping = aes(x=cut, y=depth),
    fun.ymin = min,
    fun.ymax = max,
    fun.y = median
  )
```

### 3.7.1 Exercises
<a id="top"></a>

1) What is the default geom associated with `stat_summary()`? How could you rewrite the previous plot to use that geom function instead of the stat function?

?stat_summary()

The default geom associated with `stat_summary()` is the `pointrange` geom.

?geom_pointrange()

```{r}
# create a df with the values first
diamonds_summary <- diamonds %>%
  group_by(cut) %>%
  summarize(lower = min(depth), med = median(depth), upper = max(depth))

ggplot(data=diamonds_summary) +
  geom_pointrange(mapping = aes(x=cut, y=med, ymax=upper, ymin=lower)
  ) +
  ylab("depth")
```

2) What does `geom_col()` do? How is it different to `geom_bar()`?

?geom_col

Both `geom_col` and `geom_bar` are geoms to create bar charts. The bar heights using `geom_col` represents values in the data. We need to specify two variables for each of the x and y-axes. The bar heights represent the y-axis variable's value for each of the categories on the x-axis variable.

The `geom_bar` represents the bar height proportional to the number of cases in each group. We only specify one variable for the x-axis, and the bar heights are computed to represent the count for each category.

We can look at examples of the two here.

```{r}
# bar height is proportional
ggplot(data=diamonds) +
  geom_bar(mapping=aes(x=cut))
```

```{r}
# bar height is proportional
ggplot(data=diamonds) +
  geom_col(mapping=aes(x=cut, y=depth))
```


3) Most geoms and stats come in pairs that are almost always used in concert. Read through the documentation and make a list of all the pairs. What do they have in common?

See geom cheat sheets. https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf

4) What variables does `stat_smooth()` compute? What parameters control its behaviour?

The `stat_smooth()` function adds a smooth line to data points that allows us to view patterns in the data. 

* The `method` argument allows us to choose how the smooth line is gererated with smoothing methods including "lm", "glm", "gam", "loess", or a function. 
* The `function` argument allos you to enter a smoothing function like "y ~ x". 
* `se` is a boolean to include standard errors or not

```{r}
ggplot(data=iris, aes(x=Sepal.Length, y=Petal.Width, color=Species)) +
  geom_point() +
  geom_smooth(se=TRUE)
```


5) In our proportion bar chart, we need to set `group = 1`. Why? In other words what is the problem with these two graphs?

```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = ..prop..))

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = color, y = ..prop..))
```

```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = ..prop.., group=1))

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = color, y = ..prop.., group=1))
```

Without the group argument, the geom will group the data according to the x-axis variable `cut`. Since we are interested in proportions, we need to consider al of the variables together, so we need to have them as a single group. Notice how the color argument no longer distinguished between the different cuts when we add the `group` argument.


## 3.8 Position adjustments
<a id="top"></a>

We can adjust colors in bar charts using eithe the `color` or `fill` aesthetics.

```{r}
ggplot(data=diamonds) + 
  geom_bar(mapping = aes(x=cut, color=cut))

ggplot(data=diamonds) + 
  geom_bar(mapping = aes(x=cut, fill=cut))
```

We can even map the color to another variable. The bars will reflect the data and the colors will be stacked to represent the aesthetic variable.
```{r}
ggplot(data=diamonds) +
  geom_bar(mapping = aes(x=cut, fill=clarity))
```

The stacking is done automatically by the **position adjustment** specified by the `position` argument. If you don't want a stacked barchart, you can use one of the three other options:

- `"identity"`
- `"dodge"`
- `"fill"`

The `"identity"` option places each object exactly where it falls in the context of the graph. For bar charts, this simply overlaps the bars. To see the overlapping bars, we need to adjust one of the other aesthetics, like `alpha`.
```{r}
# set the transparency of the fill using alpha
ggplot(data=diamonds, mapping=aes(x=cut, fill=clarity)) +
  geom_bar(alpha=1.5, position="identity")

# remove the fill by setting fill to NA
ggplot(data=diamonds, mapping=aes(x=cut, color=clarity)) +
  geom_bar(fill=NA, position="identity")
```

The `"fill"` option works like stacking but makes each stack of bars the same height. This makes comparing proportions easier.
```{r}
ggplot(data=diamonds) +
  geom_bar(mapping = aes(x=cut, fill=clarity), position="fill")
```

The `"dodge"` option places overlapping objects beside one another. This makes for easier comparisons between individual values.
```{r}
ggplot(data=diamonds) +
  geom_bar(mapping = aes(x=cut, fill=clarity), position="dodge")
```

One more option that is not useful for barcharts can be used with scatterplots. This is the `"jitter"` position which allows us to see overlapping points on a scatterplot. Notice in the following plot that we only see 126 points even though there are 234 observations.
```{r}
ggplot(data=mpg) +
  geom_point(mapping = aes(x=displ, y=hwy))
```

We can avoid this with the `"jitter"` option, which adds a small amount of random noise to the points on the plot.
```{r}
ggplot(data=mpg) +
  geom_point(mapping = aes(x=displ, y=hwy), position="jitter")
```

This can really help display the data on a plot. Another way to jitter points on a scatter plot is to use the `geom_jitter()` geom.

### 3.8.1 Exercises
<a id="top"></a>

1. What is the problem with this plot? How could you improve it?
```{r}
ggplot(data=mpg, mapping = aes(x=cty, y=hwy)) +
  geom_point()
```

We might want to jitter the points to view more.
```{r}
ggplot(data=mpg, mapping = aes(x=cty, y=hwy)) +
  geom_jitter()
```

Now we can see much more data on the graph.

2. What parameters to `geom_jitter()` control the amount of jittering?

The `width` and `height` parameters control the amount of horizontal and vertical jitter. The default values are 40%. We can try to play around with this setting.
```{r}
# more horizontal jitter
ggplot(data=mpg, mapping = aes(x=cty, y=hwy)) +
  geom_jitter(width=0.7)

# more veritcal jitter
ggplot(data=mpg, mapping = aes(x=cty, y=hwy)) +
  geom_jitter(height=0.7)

# less horizontal jitter
ggplot(data=mpg, mapping = aes(x=cty, y=hwy)) +
  geom_jitter(width=0.1)

# less vertical jitter
ggplot(data=mpg, mapping = aes(x=cty, y=hwy)) +
  geom_jitter(height=0.1)
```

3. Compare and contrast `geom_jitter()` with `geom_count()`.
```{r}
ggplot(data=mpg, mapping = aes(x=cty, y=hwy)) +
  geom_jitter()

ggplot(data=mpg, mapping = aes(x=cty, y=hwy)) +
  geom_count()
```

The two geoms are quite similar, with `geom_jitter` we look at the density of points to see how areas that are highly represnted and with `geom_count` we look at the size of the points instead. The benefit of `geom_count` is that the points are in their original position so we get a more accurate representation of the data, however, the true number of points is still somewhat hidden.

4. What's the default position adjustment for `geom_boxplot()`? Create a visualization of the `mpg` dataset that demonstrates it.

The default position of `geom_boxplot` is "dodge2". We can look at the `class` variable colored by `drv` to view this. 

```{r}
ggplot(data=mpg) +
  geom_boxplot(mapping = aes(x=class, y=hwy, color=drv))
```

We can try playing around with other postions as well.
```{r}
ggplot(data=mpg) +
  geom_boxplot(mapping = aes(x=class, y=hwy, fill=drv, alpha=0.2), position="identity")
```


## 3.9 Coordinate Systems
<a id="top"></a>

The default coordinate system is the Cartesian coordinate system where the $x$ and $y$ coordinates act independently to determine the location of each point. There are other coordinate systems that we can use.

`coord_flip()` switches the $x$ and $y$ axes. This comes in handy for making things like horizontal box plots.
```{r}
# vertical boxplots
ggplot(data = mpg, mapping=aes(x=class, y=hwy, fill=class)) +
  geom_boxplot(show.legend = FALSE)

# horizontal boxplots
ggplot(data=mpg, mapping=aes(x=class, y=hwy, fill=class)) +
  geom_boxplot(show.legend = FALSE) +
  coord_flip()
```

`coord_quickmap()` sets the aspect ratio correctly for maps. This is important for plotting spatial data.
```{r}
map <- map_data("world")

ggplot(map, aes(long, lat, group=group, fill=region)) +
  geom_polygon(color="black", show.legend=FALSE)

ggplot(map, aes(long, lat, group=group, fill=region)) +
  geom_polygon(color="black", show.legend=FALSE) +
  coord_quickmap()
```


`coord_polar()` uses polar coordinates. This can reveal interesting connections between a bar chart and Coxcomb chart.
```{r}
bar <- ggplot(data=diamonds) +
  geom_bar(aes(x=cut, fill=cut),
           show.legend = FALSE,
           width = 1) +
  theme(aspect.ratio=1) +
  labs(x=NULL, y=NULL)

bar + coord_flip()
bar + coord_polar()
```


### 3.9.1 Exercises 
<a id="top"></a>

1. Turn a stacked bar chart into a pie chard using `coord_polar()`
```{r}
# without polar coordinates
ggplot(data=diamonds, aes(x = factor(1), fill=cut)) +
  geom_bar(width=1)

# with polar coordinates
ggplot(data=diamonds, aes(x = factor(1), fill=cut)) +
  geom_bar(width=1)  +
  coord_polar(theta="y") +
  labs(x=NULL, y=NULL)
```

2. What does `labs()` do? Read the documentation.

`labs()` allows you to add labels to your plot. You can add a title, subtitle, caption, tag, and update the x and y axes' labels.
```{r}
ggplot(data=diamonds, aes(x = factor(1), fill=cut)) +
  geom_bar(width=1)  +
  coord_polar(theta="y") +
  labs(x=NULL, y=NULL,
       title="Proportion of Diamond Cuts",
       subtitle="A pie chart",
       caption="This pie chart shows us the proportion of diamonds with different cuts in the diamonds dataset. 
       Most diamonds are cute with the Ideal cut, followed by Premium.",
       tag="diamonds dataset"
       )
```

3. What's the difference between `coord_quickmap()` and `coord_map()`?
`coord_map()` projects a portion of the earth onto a flat 2D plane and does not typically preserve straight lines. It requires a lot fo computation.

`coord_quickmap()` approximates the projection and does preserve straight lines. It's better to use for smaller areas closer to the equator.


4. What does the plot below tell you about the relationship between city and highway mpg? Why is `coord_fixed()` important? What does `geom_abline()` do?
```{r}
ggplot(data=mpg, mapping=aes(x=cty, y=hwy)) +
  geom_point() +
  geom_abline() +
  coord_fixed()
```

This plot tells us that there is positive relationship between city miles and highway miles that a car can drive per gallon of gas. Since the points are all above the line, we see that a car always gets more highway miles than city miles.

The `abline` plots the diagonal line. We're looking at the line where city miles is equal to highway miles.


## 3.10 The layered grammar of graphics
<a id="top"></a>

Now we can develop a code template that uses all of the techniques we've learned to generat a plot with `ggplot`.
```{r, eval=FALSE}
ggplot(data = <DATA>) +
  <GEOM_FUNCTION>(
    mapping = aes(<MAPPINGS>),
    stat = <STAT>,
    position = <POSITION>
  ) +
  <COORDINATE_FUNCTION> +
  <FACET_FUNCTION>
  )
```

The seven parameters for this template compose the grammar of graphics, a formal system for building plots. This grammar is based on the insight that you can uniquely describe any plot as a combination of a dataset, a geom, a set of mappings, a stat, a position adjustment, a coordinat system, and a faceting scheme.

# Chapter 4 Workflow: basics
<a id="top"></a>

This chapter is pretty basic stuff so I'm going to skip it. See the R For Data Science book for the details: https://r4ds.had.co.nz/workflow-basics.html.

These are the topics covered in this chapter:
- 4.1 coding basics
- 4.2 variable naming conventions
- 4.3 functions


# Chapter 5 Data transformations
<a id="top"></a>

## 5.1 Introduction
<a id="top"></a>

### 5.1.1 Prerequisites
<a id="top"></a>

We'll be using the `nycflights13` package.
```{r}
library(nycflights13)
library(tidyverse)
```

## 5.1.2 nycflights13
<a id="top"></a>

We'll be using the `flights` dataframe from the `nycflights13` package. This dataframe contains all 336,776 flights that departed from New York City in 2013. This data frame comes from the Bureau of Transportation Statistics.

```{r}
head(flights)
```

The data is actualy in *tibble* form. A tibble is a dataframe that is slightly tweaked to work better in the tidyverse. More details on tibbles will be in the *wrangle* section.

### 5.1.3 dplyr basics
<a id="top"></a>

This chapter will introduce the five key `dplyr` functions that will allow us to solve the vast majority of data manipulation challenges.

- Pick observations by their values: `filter()`
- Reorder the rows: `arrange()`
- Pick variables by their names: `select()`
- Create new variables with functions of existing variables: `mutate()`
- Collapse many values down to a single summary: `summarise()

These can all be used with `group_by()` which changes the scope of each function from operating on the entire dataset to operating on it group-by-group. These six functions provide the verbs for a language of data manipulation.

All verbs work similary:

1. The first argument is a data frame.
2. The subsequent arguments describe what to do with the data frame, using the variable names (without quotes).
3. The result is a new data frame.



## 5.2 Filter rows with `filter()`
<a id="top"></a>

`filter()` allows you to subset observations based on their values. The first argument is the dataframe. The second and subsequent arguments are the expressions that filter the dataframe.

For example, we can select all the flights on January 1st with:
```{r}
filter(flights, month==1, day==1)
```

We can store the filtered dataframe in a variable.
```{r}
jan1 <- filter(flights, month==1, day==1)
```


### 5.2.3 Logical operators
<a id="top"></a>

We can use logical operators with `filter` to do more complex commands. Say we wanted to get all flights in November or December. We could do
```{r}
filter(flights, month==1 | month==12)
```

A useful short-hand for this is `x %in% y`. This allows us select every row where $x$ is one of the values in $y$. We can rewrite the code above as
```{r}
nov_dev <- filter(flights, month %in% c(11,12))
```

### 5.2.3 Missing Values
<a id="top"></a>

`filter()` only includes rows where the condition is true. If you want to keep `NA` values then ask for them explicitly.
```{r}
# create a tibble
df <- tibble(x = c(1, NA, 3))
# doesn't return NA
filter(df, x>1)
# returns NA rows
filter(df, is.na(x) | x>1)
```

### 5.3.4 Exercises
<a id="top"></a>

1. Final all flights that
  1. Had an arrival delay of two or more hours
```{r}
filter(flights, arr_delay >= 2)
```

  2. Flew to Houston (IAH or HOU)
```{r}
filter(flights, dest=='HOU' | dest=='IAH')
```

  3. Were operated by United, American, or Delta  
```{r}
# find out abbreviations for airlines
?flights

# airlines are stored in the airlines tibble
airlines

# filter data frame with UA, AA, DL
filter(flights, carrier %in% c('UA', 'AA', 'DL'))
```

  4. Departed in summer (July, August, and September)
```{r}
filter(flights, month %in% c(7,8,9))
```
  
  5. Arrived more than two hours late, but didn't leave late
```{r}
filter(flights, dep_delay<=0, arr_delay>2)
```

  6. Were delayed by at least an hour, but made up over 30 minutes in flight.
```{r}
filter(flights, dep_delay>=1, dep_delay-arr_delay >= 30)
```

  7. Departed between midnight and 6am (inclusive)  
```{r}
filter(flights, dep_time <= 600)
```

2. Another useful `dplyr` filtering helper is `between()`. What does it do? Can you use it to simplify the code needed to answer the previous challenges?

`between(x, left, right)` is a shortcut for `x >= left` and `x <= right`. We can definitely shorten part 4: departed in summer (between july and september)
```{r}
# challenge 4
filter(flights, between(month, 7, 9))
```

The rest are already simpler.

3. How many flights have a missing `dep_time`? What other variables are missing? What might these rows represent?
```{r}
(no_dep <- filter(flights, is.na(dep_time)))
```

There are 8,255 flights missing `dep_time`. These are missing `arr_time` and `air_time`. These may be flights that were canceled and never took off.

4. Why is `NA ^ 0` not missing? Why is `NA | TRUE` not missing? Why is `FALSE & NA` not missing? Can you figure out the general rule? (`NA * 0` is a tricky counterexample!)
```{r}
NA^0 # = 1

NA | TRUE # TRUE

FALSE & NA # FALSE

NA * 0 # NA

```

We get a solution for the first three because no matter what value of the `NA` is, the solution will be the same. Imagine the `NA` was infinity in the first statement, then the answer is still 1. For the second statment `NA | TRUE`, we only need one side to be true and the entire is statement is true. Thus, it doesn't matter what the NA value is. Then in the third statement `FALSE & NA`, we need both sides to be true and since one is already FALSE, then the entire statement is false regardless of what the NA value is. Finally, the `NA * 0` statement doesn't work because most of the time 0 times a number is 0, however if the NA were infinity, the answer is not zero.
```{r}
Inf * 0
```
This mean that we cannot get an answer for this statement.



## 5.3 Arrange rows with `arrange()`
<a id="top"></a>

`arrange()` works similarly to `filter()` except it changes the order of the rows. It takes a data frame and a set of column names to order by. If you provide more than one column name, each additional column will be used to break ties in the values of the preceding column.

```{r}
arrange(flights, year, month, day)
```

Use `desc()` to re-order a column in descending order.
```{r}
arrange(flights, desc(dep_delay))
```

Missing values are always sorted at the end.
```{r}
df <- tibble(x = c(5,2,NA))
arrange(df, x)

arrange(df, desc(x))
```

### 5.3.1 Exercises
<a id="top"></a>

1. How could you use `arrange()` to sort all missing values to the start? (Hint: use `is.na()`)
```{r}
df <- tibble(x = c(1,NA,2,3,NA,4,5,NA))

# sort in descending order, with is.na()
arrange(df, desc(is.na(x)))
```

2. Sort `flights` to find the most delayed flights. Find the flights that left earliest.
```{r}
# sort the departure delays in descending order
arrange(flights, desc(dep_delay))
```

3. Sort `flights` to find the fastest (highest speed) flights.
```{r}
# sort by distance traveled divided by time spent in the air
arrange(flights, distance/air_time)
```

4. Which flights travelled the farthest? Which travelled the shortest?
```{r}
# sort by distance for shortest flights
arrange(flights, distance)
```

```{r}
# sort by descending distance for farthest flights
arrange(flights, desc(distance))
```


## 5.4 Selection columns with `select()`
<a id="top"></a>

`select()` allows you to zoom in on a useful subset of columns using operations baed on the names of the variables.

```{r}
# select columns by names
select(flights, year, month, day)
```

```{r}
# select all columns between year and day
select(flights, year:day)
```

```{r}
# select all columns except for those from year to day (inclusive)
select(flights, -(year:day))
```

There are some other useful helper functions that you can use with `select()`:

- `starts_with(abc)` matches names that begin with "abc"
- `ends_with(xyz)` matches names that end with "xyz"
- `contains("ijk") matches names that contain "ijk"
- `matches("(.)\\1") selects variables that match a regular expression. This one matches any variables that contain repeated characters.
- `num_range("x", 1:3)` matches `x1`, `x2`, `x3`

Se more in `?select`

`select()` can also be used to rename variables, but is rarely useful because it drops all of the variables not explicitly mentioned. Instead, use `rename()`, a variant of `select()` that keeps all the variables that aren't explicitly mentioned.

```{r}
rename(flights, date=day)
```

Another option is to use `select()` with `everything()`. This is useful if you have a handful of variables that you'd like to move to the start of the data frame.

```{r}
select(flights, time_hour, air_time, everything())
```

### 5.4.1 Exercises
<a id="top"></a>

1. Brainstorm as many ways as possible to select `dep_time`, `dep_delay`, `air_time`, and `arr_delay` from `flights.

```{r}
# using select()
select(flights, dep_time, dep_delay, arr_time, arr_delay)
```

```{r}
# using select() with helper function starts_with()
select(flights, starts_with("dep"), starts_with("arr"))
```

```{r}
# use select() with ends_with() and starts_with()
select(flights, ends_with("delay"), ends_with("time"), -starts_with(c("sched", "air")))
```

2. What happens if you include the name of a variable multiple times in a `select()` call?
```{r}
select(flights, year, year)
```

If you include a variable multiple times in select, the variables will only be selected once.

3. What does the `any_of()` function do? Why might it be helpful in conjunction with this vector?
```{r}
vars <- c("year", "month", "day", "dep_delay", "arr_delay")
```

The `any_of()` function will select any of the columns using a vector. As opposed to the `all_of()` function, `any_of()` will not throw an error if the vector contains names that are not found as columns in the data frame.

```{r}
select(flights, any_of(vars))
```

4. Does the result of running the following code suprise you? How do the select helpers deal with case by default? How can you change the default?
```{r}
select(flights, contains("TIME"))
```

The helpers ignore case by default. To change this behaviour we can use the `ignore.case` argument.
```{r}
select(flights, contains("TIME", ignore.case=FALSE))
```


## 5.5 Add new variables with `mutate()`
<a id="top"></a>

We can add new columns that are functions of existing columns using `mutate()`. This will add new columns at the end of the dataset.

```{r}
# create a dataframe with less columns
flights_sml <- select(flights, year:day, ends_with('delay'), distance, air_time)

# add new columns with mutate()
mutate(flights_sml, 
       gain = dep_delay - arr_delay,
       speed = distance / air_time * 60)
```

Note that you can refere to the columns that you just created.
```{r}
mutate(flights_sml,
       gain = dep_delay - arr_delay,
       hours = air_time / 60,
       gain_per_hour = gain / hours)
```

If you only want to keep the new variables, use `transmute()`.
```{r}
transmute(flights, 
          gain = dep_delay - arr_delay,
          hours = air_time / 60,
          gain_per_hour = gain / hours)
```

### 5.5.1 Useful creation functions
<a id="top"></a>

There are many functions you might use with the `mutate()` function. Here are some useful ones.

- arithmetic operators: `+`, `-`, `*`, `/`, `^`
- modular arithmentic: `%/%` (integer division) and `%%` (remainder)
- logs: `log()`, `log2()`, `log10()`
- offsets: `lead()` and `lag()` allow you to refer to the leading or lagging values.
```{r}
(x <- 1:10)

lag(x)

lead(x)

# use this to compute runnign differences
x-lag(x)

# find when value changes
x != lag(x)
```

- cumulative and rolling aggregates: `cumsum()` (cumulative sum), `cumprod()` (cumulative product), `cummin()` (cumulative min), `cummax()` (cumulative max), `cummean()` (cumulative mean).
```{r}
x

cumsum(x)

cumprod(x)

cummin(x)

cummax(x)

cummean(x)
```

- logical comparisons: `<`, `<=`, `>`, `>=`, `!=`, `==`
- ranking 
```{r}
y <- c(1,2,2,NA,3,4)

# rank in order
min_rank(y)

# rank in reverse order
min_rank(desc(y))
```

Here are some variants of the standard ranks.
```{r}
row_number(y)

dense_rank(y)

percent_rank(y)

cume_dist(y)
```

### 5.5.2 Exercises

1. Currently `dep_time` and `sched_dep_time` are convenient to look at, but hard to compute with because they're not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight.
```{r}
# make a smaller data frame
flights_sml <- select(flights, dep_time, sched_dep_time)

# multiply hours by 60 and add to minutes
# time is formatted as HHMM or HMM
mutate(flights_sml,
       new_dep_time = dep_time %/% 100 * 60 + dep_time %% 100,
       new_sched_dep_time = sched_dep_time %/% 100 * 60 + sched_dep_time %% 100
       )
```

2. Compare `air_time` with `arr_time - dep_time`. What do you expect to see? What do you see? What do you need to do to fix it?

I would expect to see the duration of the flight.

```{r}
flights_sml <- select(flights, arr_time, dep_time, air_time)

mutate(flights_sml,
       duration = arr_time - dep_time)
```

The computed duration doesn't match the `air_time` in the table. This format doesn't allow us to do a subtraction because it's written in HMM format. We can convert to minutes like we did previously. These times are also recorded in the local timezone, so need to take this into account to get an accurate flight duration.

3. Compare `dep_time`, `sched_dep_time`, and `dep_delay`. How would you expect those three numbers to be related?
```{r}
select(flights, dep_time, sched_dep_time, dep_delay)
```

I would expect that `dep_delay` is the result of subtracting `sched_dep_time` from `dep_time`. We can add a column to verify this.
```{r}
mutate(select(flights, dep_time, sched_dep_time, dep_delay), 
       difference = dep_time - sched_dep_time)
```

It looks like the calculation works for determing `dep_delay` from the other two columns.

4. Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefuly read the documnetation for `min_rank()`.

```{r}
# add column for min rank
# filter by min rank column
# sort by the rank column
flights %>%
   mutate(flights, dep_rank=min_rank(dep_delay)) %>%
  filter(dep_rank <= 10) %>%
  arrange(dep_rank)
```

`min_rank()` does not break ties, but instead assigned the same rank to equal values. We could also use `row_number()` which breaks ties by giving a lower rank to the value that is encountered first. We can try `row_number()` and see how the answer changes.
```{r}
# add column for row_number()
# filter by row_number column
# sort by the row_number column
flights %>% 
  mutate(flights, dep_rank=row_number(dep_delay)) %>%
  filter(dep_rank <= 10) %>%
  arrange(dep_rank)
```

Now we have exactly 10 flights since we broke ties with the `row_number()` function, whereas we had 12 flights using the `min_rank()` function. Depending on our needs, we might prefer one method over the other.

5. What does `1:3 + 1:10` return? Why?
```{r}
# 1:3 + 1:10
```

We get an error when we try to run this, saying that the longer object length is not a multiple of shorter object length. `R` is trying to apply the vector addition by vectorizing the input but does not know how. We can try to fix this by making the longer vector's length a multiple of the shorter vector length.
```{r}
1:3 + 1:12
```

Now we get the vector `1:12` with the vector `1:3` repeated 4 times, and added across the 12 numbers. The shorter vector was repeated to make the length of the longer vector to complete the addition operation. This is similar to adding a scalar to a vector and having the scalar become a vectorized version of itself.

6. What trigonometric functions does R provide?

You can access the trigonometric functions documentation by typing `?Trig`. R provides the following trig functions:

- `cos(x)`
- `sin(x)`
- `tan(x)`
- `acos(x)`
- `asin(x)`
- `atan(x)`
- `atan2(y,x)`
- `cospi(x)`
- `sinpi(x)`
- `tanpi(x)`


## 5.6 Grouped summaries with `summarise()`
<a id="top"></a>

The last key verb is `summarise()`. It collapses a dataframe to a single row.
```{r}
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
```

`summarise()` is more usefule when paired with `group_by()`. This changes the unit of analysis from the entire dataframe to the individual groups. We can apply the same function to the grouped dataframe to get the average delay per date.
```{r}
group_by(flights, year, month, day) %>%
  summarise(delay = mean(dep_delay, na.rm = TRUE))
```

### 5.6.1 Combining multiple operations with the pipe
<a id="top"></a>

Not going to go through this. See R4ds book online.


### 5.6.2 Missing values
<a id="top"></a>
The `na.rm` flag is used to remove NA values before the computation. Alternatively, we can filter the NA values out of the dataframe prior to summarizing.

```{r}
not_cancelled <- flights %>%
  filter(!is.na(dep_delay), !is.na(arr_delay))

not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(mean = mean(dep_delay))
```

### 5.6.3 Counts
<a id="top"></a>

Whenever you do any aggregation, it's always a good idea to include either a count (`n()`) or a count of non-missing values (`sum(is.na(x))`). That way you can check that you're not drawing conclusions based on very small amounts of data. For example, let's look at the planes that have the highest average delays.
```{r}
delays <- not_cancelled %>% 
  group_by(tailnum) %>%
  summarize(
    delay = mean(arr_delay)
  )

ggplot(data = delays, mapping = aes(x = delay)) +
  geom_freqpoly(binwidth = 10)
```


We get more information if we draw a scatterplot of number of flights vs. average delay.
```{r}
delays <- not_cancelled %>%
  group_by(tailnum) %>%
  summarise(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )


ggplot(data = delays, mapping = aes(x=n, y = delay)) +
  geom_point(alpha = 1/10)
```


Now we see that there is much greater variation in the average delay when there are few flights. Typicaly, when you plot a mean (or other summary) vs. group size, you'll see the variation decreases as the sample size increases.

When looking at this type of plot, it's often useful to filter out the groups with the smallest numbers of observations, so you can see more of the pattern and less of the extreme variation in the smallest groups. This is what the following code does, as well as showing you a handy pattern for integrating ggplot2 into dplyr flows. 

```{r}
delays %>%
  filter(n > 25) %>%
  ggplot(mapping = aes(x = n, y = delay)) +
  geom_point(alpha = 1/10)
```


There is another common variation of this type of pattern. Let's look at how the average performance of batters in baseball is related to the number of time they're at bat. 

```{r}
library(Lahman)

# convert to a tibble so it prints nicely
batting <- as.tibble(Lahman::Batting)

batters <- batting %>%
  group_by(playerID) %>%
  summarise(
    ba = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE), # batting average
    ab = sum(AB, na.rm = TRUE) # at bat
  )

batters %>%
  filter(ab > 100) %>%
  ggplot(mapping = aes(x=ab, y=ba)) +
  geom_point() +
  geom_smooth(se = FALSE)
```

Note:
1. The variation in our aggregate decreases as we get more data points
2. There's a positive correlation between skill (`ba`) and oppotunities to hit the ball (`ab`). This is because teams control who gets to play, and obviously pikc their best players.


### 5.6.4 Useful summary functions
<a id="top"></a>

It is sometimes useful to combine aggregation with logical subsetting.
```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(
    avg_delay1 = mean(arr_delay),
    avg_delay2 = mean(arr_delay[arr_delay > 0]) # the average positive delay
  )
```

Measures of spread are also useful.

- standard deviation: `sd()`
- interquartile range: `IQR()`
- median abosulation deviation: `mad()`

```{r}
# why is the distance to some destinations more variables than others?
not_cancelled %>%
  group_by(dest) %>%
  summarise(distance_sd = sd(distance)) %>%
  arrange(desc(distance_sd))
```


Measures of rank:

- minimum: `min()`
- quantiles: `quantile()`
- maximum: `max()`

```{r}
# when do the first and last flights leave each day?
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(
    first = min(dep_time),
    last = max(dep_time)
  )
```

Measures of position:

- choose first: `first()`
- choose nth: `nth()`
- choose last: `last()`

```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(
    first_dep = first(dep_time),
    last = last(dep_time)
  )
```

These functions are complementary to filtering on ranks. Filtering gives you all variables, with each observation in a separate row.

```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  mutate(r=min_rank(desc(dep_time))) %>%
  filter(r %in% range(r))
```


Counts:

- count non-missing values: `sum(!is.na())`
- count distinct (unique) values: `n_distinct()`

```{r}
not_cancelled %>%
  group_by(dest) %>%
  summarise(carriers = n_distinct(carrier)) %>%
  arrange(desc(carriers))
```

dplyr provides a simple helper if all you want is a count.
```{r}
not_cancelled %>%
  count(dest)
```


You could also use a wegiht variable. For example, you could use this to sum the total number of miles a plane flew.
```{r}
not_cancelled %>%
  count(tailnum, wt = distance)
```

Counts and proportions of logical values:

```{r}
# how many flights left before 5am?
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(n_early = sum(dep_time < 500))

# what proportion of flights are delayed by more than an hour?
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(hour_prop = mean(arr_delay > 60))
```


### 5.6.5 Grouping by multiple variables
<a id="top"></a>

When you group by multiple variables, each summary peels off one level of the grouping. That makes it easy to progressively roll up a dataset.
```{r}
daily <- group_by(flights, year, month, day)
(per_day <- summarise(daily, flights=n()))

(per_month <- summarise(per_day, flights=sum(flights)))

(per_year <- summarise(per_month, flights = sum(flights)))
```

### 5.6.6 Ungrouping
<a id="top"></a>

If you need to remove grouping, and return to operations on ungrouped data, use `ungroup()`
```{r}
daily %>%
  ungroup() %>%
  summarise(flights = n())
```

### 6.5.7 Exercises

1. Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. Consider the following scenarios:

- a flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.
```{r}
not_cancelled %>%
  group_by(flight) %>%
  summarise(
    early_prop = mean(arr_delay < 0),
    late_prop = mean(arr_delay > 0)
  ) %>%
  filter(
    early_prop == 0.5,
    late_prop == 0.5
  )
```


- a flight is always 10 minutes late
```{r}
not_cancelled %>%
  group_by(flight) %>%
  summarise(
    late_prop = mean(arr_delay > 0)
  ) %>%
  filter(
    late_prop == 1
  )
```


- a flights is 30 minutes early 50% of the time, and 30 minutes late 50% of the time
```{r}
not_cancelled %>%
  group_by(flight) %>%
  summarise(
    early_30 = mean(arr_delay == -30),
    late_30 = mean(arr_delay == 30)
  ) %>%
  filter(
    early_30 == 0.5,
    late_30 == 0.5
  )
```

- 99% of the time a flight is on time. 1% of the time it's 2 hours late.
```{r}
not_cancelled %>%
  group_by(flight) %>%
  summarise(
    early_prop = mean(arr_delay == 0),
    late_prop = mean(arr_delay == 2 * 60)
  ) %>%
  filter(
    early_prop == 0.99,
    late_prop == 0.01
  )
```


Which is more important: arrival delay or departure delay?

We use arrival depature to compute all of these.


2. Come up with another approach that wil give you the same output as `not_cancelled %>% count(dest)` and `not_cancelled %>% count(tailnum, wt = distance)` (without using `count()`)
```{r}
# match the first command using n() with summarise()
counts <- not_cancelled %>% count(dest)

summarise_counts <- not_cancelled %>%
  group_by(dest) %>%
  summarise(summarise_n = n())

full_join(counts, summarise_counts)

# match the second command using sum() and summarise()
sums <- not_cancelled %>% count(tailnum, wt=distance)

summarise_sums <- not_cancelled %>%
  group_by(tailnum) %>%
  summarise(summarise_n = sum(distance))

full_join(sums, summarise_sums)
```


3. Our definition of cancelled flights (`is.na(dep_delay) | is.na(arr_delay)`) is slightly suboptimal. Why? Which is the most important column?

`arr_delay` is the most important column because there seems to be flights with `dep_delay` entries even though the `arr_delay` is NA.
```{r}
# arr_delay is NA but dep_delay is not NA
filter(flights, 
       is.na(arr_delay),
       !is.na(dep_delay))

# dep_delay is NA but arr_delay is not NA - no flights here
filter(flights,
       is.na(dep_delay),
       !is.na(arr_delay))
```


4. Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay?
```{r}
flights %>%
  group_by(year, month, day) %>%
  summarise(
    prop_cancelled = mean(is.na(arr_delay)), # proportion cancelled
    avg_delay = mean(dep_delay, na.rm = TRUE)
  ) %>%
  ggplot(aes(x=prop_cancelled, y=avg_delay)) +
  geom_point()
```

There seems to be a slight positive relationship between `avg_delay` and `prop_cancelled`, however there are some outlier days.


5. Which carrier has the worst delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about `flights %>% group_by(carrier, dest) %>% summarise(n)))`


We have to decide whether departure or arrival delays are more important. Let's check the relationship between the two.
```{r}
ggplot(flights) +
  geom_count(aes(x=arr_delay,
                 y=dep_delay,
                size=..n..,
                color=..n..)) +
  guides(color = 'legend') +
  geom_abline(slope=1, color='red')
```

The two types of delays are quite similar with no obvious pattern of one being less than the other. It looks like there are more points under the red line, indicating that arrival delays tend to be shorter than departure delays. This makes sense because time can be made up during a smooth flight. It's probably more important to people if they arrive at their destination on time, so we'll go with arrival time.

```{r}
flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(carrier) %>%
  summarise(max_delay = max(dep_delay)) %>%
  arrange(desc(max_delay))
```

We remove the flights with NA values for arrival delay since we can't do anything with those. We see that carriers with the worst delays are HA, MQ, and AA.


Now we'll try disentagling effects of bad airports vs. bad carriers. We'll group by the carrier and origin airport to find the max delays between these pairs. Then we can pass the results to `ggplot` so we can easily visualize them as a heatmap. We're still seeing HA and MQ carriers stand out, and JFK airport seems to have a lot of arrival delays. We could follow the same procedure for destination airports as well.

```{r}
flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(carrier, origin) %>%
  summarise(max_delay = max(dep_delay)) %>%
  arrange(desc(max_delay)) %>%
  ggplot() +
  geom_tile(aes(x=origin,
                y=carrier,
                fill=max_delay))
```



6. What does the `sort` argument to `count()` do. When might you use it?

The `count()` function will count the unique values of one or more variables, and the `sort` argumnet will display the largest groups at the top.

```{r}
flights %>%
  count(carrier, sort=TRUE)
```


## 5.7 Grouped mutates (and filters)
<a id="top"></a>

Grouping is most useful in conjunction with `summarise()`, but you can also do convenient operations with `mutate()` and `filter()`.

Find the worst members of each group:
```{r}
flights %>%
  group_by(year, month, day) %>%
  filter(rank(desc(arr_delay)) < 10)
```

Find all groups bigger than a threshold
```{r}
popular_dests <- flights %>%
  group_by(dest) %>%
  filter(n() > 365)
popular_dests
```

Standardise to compute per group metrics
```{r}
popular_dests %>%
  filter(arr_delay > 0) %>%
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>%
  select(year:day, dest, arr_delay, prop_delay)
```


### 5.7.1 Exercises
<a id="top"></a>

1. Refer back to the lists of useful mutate and filtering functions. Describe how each operation changes when you combine it with grouping.


2. Which plane (tailnum) has the worst on-time record?
```{r}
flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(tailnum) %>%
  mutate(max_delay=max(arr_delay)) %>%
  arrange(desc(max_delay)) %>%
  select(tailnum, max_delay) %>%
  unique()
  
```

The worse on-time record is held by flight N384HA with a 1272 arrival delay.

3. What time of day should you fly if you want to avoid delays as much as possible?
```{r}
flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(sched_dep_time) %>%
  summarise(avg_delay = mean(arr_delay)) %>%
  arrange(desc(avg_delay))
```

The worst average delay occurs with flights that are scheduled to depart at 2207.

4. For each destination, compute the total minutes of delay. For each flight, compute the proportion of the total delay for its destination.
```{r}
flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(tailnum) %>%
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>%
  select(tailnum, arr_delay, prop_delay)
```


5. Delays are typically temporally correlated: even once the problem that caused the inital delay has been removed, later flights are delayed to allow earlier flights to leave. Using `lag()`, explore how the delay of a flight is related to the delay of the immeidately preceding flight.

```{r}
flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(origin) %>%
  arrange(sched_dep_time) %>%
  mutate(prev_delay = lag(arr_delay)) %>%
  select(flight, arr_delay, prev_delay) %>%
  ggplot() +
  geom_point(aes(x=prev_delay,
                 y=arr_delay))
```

The y-axis shows the arrival delay for a particular flight, and the x-axis shows the arrival delay for the flight that was scheduled to depart just before it from the same origina airport. The plot doesn't really show a strong relationship between the arrival delay of flights and the flights that departs immediately before.

6. Look at each destination. Can you find flights that are suspicously fast? (i.e. flights that represent a potential data entry error). Compute the air time of a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?

```{r}
flight_speed <- flights %>%
  select(flight, tailnum, origin, dest, air_time, distance) %>%
  mutate(speed =  distance / (air_time/60)) %>%
  arrange(desc(speed))

flight_speed
```

We compute the speed of each flight by taking the distance traveled (`distance`) divided by the time spend in the air (`air_time`). The air time is in minutes, so we divide by 60 to get speed in miles per hour. We can look at the distribution of flight speeds to find outliers.

```{r}
summary(flight_speed$speed)
```

It looks like the median flight speed is about 404 miles per hour, and 75% of flights are flying under 438 miles per hour. This suggests that our fastest flights at about 600-700 miles per hour are quite fast compared to average flights. 

We can now look at each flight's air time in a destination-specific manner.

```{r}
flights %>%
  group_by(origin, dest) %>%
  filter(!is.na(air_time)) %>%
  mutate(time_diff = air_time - min(air_time)) %>%
  arrange(desc(time_diff)) %>%
  select(carrier:air_time, time_diff) %>%
  group_by(origin, dest) %>%
  slice(1) %>%
  arrange(desc(time_diff))
```

We group by the origin and destination so we can compare similar flights. Then compute the difference between air time and the minimum air time for flights on the same route. Then we can sort and take the flight with the largest time difference. Here we see that the largest time difference occurs for flight 841 from JFK to SFO. 


8. For each plane, count the number of flights before the first delay of greater than 1 hour.

```{r}
delayed <- flights %>%
  group_by(tailnum, year, month, day) %>%
  arrange(dep_time) %>%
  summarise(num_prior_delay = sum(arr_delay < 60),
          num_delayed = sum(arr_delay > 60),
          prop_prior_delayed = num_prior_delay / (num_delayed + num_prior_delay)) %>%
  select(tailnum, year, month, day, num_prior_delay, num_delayed, prop_prior_delayed)
delayed
```

These show the number of flights that were delayed, the number of flights prior to the delay, and the proportion of flights that occurred prior to the delay of one hour. This code assumes that once a flight is delayed by 1 hour in a specific day, it is never returns back to schedule. We can look at a summary of these numbers.
```{r}
summary(delayed)
```

It looks like there is typically 1 flights before a plane is delayed by 1 at least one hour, with a maximum of 5 flights prior to the first 1 hour delay. However, it seems that most of the flights are not delayed by more than one hour in a specific day. 

<a id="top"></a>

